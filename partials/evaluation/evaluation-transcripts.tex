The \ivfsystem{} was evaluated based on the implemented functions.
These functions are structured to the research workflow as described in \silvia{more explicit: figure? the introduction of section \ref{system-functionality}}. This workflow will now be referred to as the `process' of the system.
\silvia{?While evaluating found problems break down into fundamental flaws in the process and design flaws.}

For the purpose of the evaluation the \ivfsystem{} code was running in the local environment of a laptop.
No connection to the internet was necessary for testing, therefore performance issues were out of the question.
The used dataset was randomly generated (random strings of letter characters), both because the \projectdata{} was not available yet and for privacy reasons.
Screenshots of the running gateway are shown in figures \ref{fig:standard-view-website} and \ref{fig:sunburst-view-zoom-website}.

\begin{figure}[!b]
	\centering
	\includegraphics[width=1.0\linewidth]{images/standard-view}
	\caption{
		Running \ivfsystem{} data management view, this view shows the standard display of the data (\ie{} summary on top and raw data at the bottom).
	}
	\label{fig:standard-view-website}
\end{figure}

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.7\linewidth]{images/sunburst-closeup}
	\caption{
		Running \ivfsystem{} data graph view, this view shows the (sunburst) graph display of the data.
	}
	\label{fig:sunburst-view-zoom-website}
\end{figure}

All evaluations were done in an informal open-talk setting with no predefined questions.
First, the purpose of the meeting was explained in a few sentences.
Each user had to perform tasks using the prototype according to the assigned case: researcher, committee, administrator.
There were three testers, and some were assigned two cases because they fit in the field of experience of the respective user role.

Tasks were described according to the system schema found in the brainstorm presented in figure \ref{fig:brainstorm-after}.
The interviewer only gave directions during the evaluation after the tester indicated that they did not know how to proceed.
If the tester struggled with a task the interviewer tried to encourage the tester to think aloud.
From this the process bottlenecks and design flaws of the system were identified.
Also, testers were asked to suggest design or process alternatives.

The  cases presented below are loose transcripts of the evaluation sessions.
After these the identified problems and possible improvements are summarised in section \ref{evaluation-summary}.

\section{Evaluation transcripts}

\paragraph{Researcher Role}
From all the cases this is arguably the largest as it has the most extensive (implemented) functions.
Therefore, all the testers performed the researcher tasks to find more flaws or give more support to flaws found with both testers.
The tasks that had to be performed were: search the data dictionary for headers, use these data headers to compose and submit a request, download the requested data.

Finding the data dictionary was not a big problem for the testers.
The next step is filtering, which is relatively easy as the input is text based and the search itself is fuzzy.
Dictionary items can be sought for based on name, description, and keywords.
Because in the prototype the descriptions are nonsense, it was difficult to find the wanted data headers.
Two of the testers did not notice that the search is instantaneous (like google search).
This resulted in pressing enter and clicking the `apply filter' button multiple times before noticing that the data had already changed at the bottom of the screen.
One of the testers prefers to search the data analogically (\ie{} print the data) and later select the wanted items in the interface.

The filter function plus the nonsense data made it rather hard for the testers to find the desired headers, they were asked to select a couple of random headers to start a request with.
Selection was straight-forward but the testers did not notice that selected items were added to the basket.
Therefore, two asked `how do I keep this selection when I start searching again?'.
This also resulted in two of the testers using the `select all' function on the basket. 
Clicking this will make a selection of \emph{all} the items in the workspace, basically overwriting the previous basket and losing all the progress.

To proceed in the task of making a request the testers looked for a button on the basket.
However, the buttons are specific to a raw data view and do not make sense in a dictionary view of the system.
The testers needed to be explained that the basket is kept in the back of the system and can be used over multiple views.
Clicking the request button at the top left of the screen is the correct action, then selecting `new request' results in a form with the basket attached showing which items were selected.

Data download is straight-forward, this is done by going to the correct workspace from the menu on the left, selecting the wanted items (or select all), and clicking the `download' button.
No problems were found here, however one of the testers noted that in principle \emph{all} data will be downloaded every time.

\paragraph{Committee Member Role}
The committee tasks are the shortest as the list only contains the request approval function. 
It breaks down into finding the requests which are open for approval, evaluating them against already approved requests, and voting.
Viewing requests that are ready for approval is done by selecting the `request' button from the left menu.
Now a list is shown of all these requests and the data that is necessary for making the decision.
Approval is given (or not) by selecting a approve or disprove button, a vote remains open for change until all committee members have casted their vote.
What vote was cast is shown both with a symbol (V/X) as with a colour (green/red) which was directly clear to the tester.

Communication functions are built into the view.  
Clicking on one of the requests redirects to `new message', the user can create a message which (upon hitting send) is automatically send to all committee members.
There was a suggestion to add a comments thread to the request itself, instead of the separate message construction.
Furthermore, the redirect was confusing for the tester as the expectation was that it would lead to more information on the request, even though all the available information was already shown.

\paragraph{Data administrator Role}
Lastly, the data administrator performed the user management functions.
The user overview is not complex in functionality, a list of users is shown.
Each with buttons to perform the following actions: make committee member, make active, approve.
This was clear and would be easy to use in a real-life scenario.
However, the tester noted that there are some process flaws.
If one of the users of the system changes institutions most of the time the data manager is not informed, this is left to the P.I.s.
Therefore the system should contain support functions for non-administrators to view the list of users and communicating with the data manager about what actions should be taken.
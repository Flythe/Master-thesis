\paragraph{What is big data?}
With the buzzword `big data' people often associate terms like size, volume, and analytics.
However there are a lot of data challenges which can lead to data being classified as big data.
McAfee describes it as `volume, velocity, variety' \cite{dsb1mcafee}, lots of data coming in at a high pace from many different sources.
Jacobs thinks it is a changing perspective of technical possibilities.
In the 1980s 100GB of data was considered big, now the perspective has changed, what you try to do with the data makes it big or not \cite{dsb5jacobs}.
Lynch makes it a problem of `lasting', how do we model and keep the registered (sometimes unique) events \cite{dsb3lynch}.

There are wide gaps between these definitions but also similarities.
One spanning idea about big data is that it can help understand specific domains and help make decisions \cite{dsb2lohr}.
Jacobs even states that transactions and storage of data are already largely solved problems \cite{dsb5jacobs}.
This leaves decision making, modelling, and lastingness as the main challenges.

Big data in the corporate world mostly means management and quick reaction on real life events.
Data-driven decisions are better than expert-opinion decisions \cite{dsb1mcafee}. 
A good example being flu prediction, Google is faster at predicting hospital visits related to flu than the official government sources \cite{dsb8dugas, dsb1mcafee}.

The modelling of data reflects the event in the real world which is of importance for data interpretation.
The last challenge is lastingness, \eg{} losing data can be of significance as each event is unique and will not reoccur.
There are also side effects, keeping any data (specifically medical) on persons raises privacy challenges \cite{dsb1mcafee}.

\paragraph{The data challenge}
In the context of the \project{} two of the big data factors lead to challenges, decision making and lastingness.
These are mainly human related or procedural, \eg{} ethics, trust, expectancy, lack of organisational support, etc.
Modelling of data is (currently) quite straight forward, mainly data has to be ready as input material for popular statistical software like SPSS or R.
Introducing computerised decision making may result in semantic or metadata problems, but compared to others these can be handled quite easily.

%Currently, in the case of the \project{}, decision making is currently left for researchers.
In the current workspace researchers make decisions on many levels, \eg{} what relevant hypotheses exist, which research hypothesis to pursue, what data should be analysed, how data should be interpreted.
Many of these decisions can be supported with computerised systems.
For example a hypothesis sweep can be executed with data mining operations, finding correlation in the data.
However, clinical researchers hold on to generation of hypothesis based on expertise, possibly leading to missed (important) conclusions.
This might describe a trust or expectancy issue with computerised systems, or the value of such a system was never shown.

On the other hand are the problems lastingness poses.
Funding bodies demand more of researchers considering data-management and sharing \cite{dsb3lynch}.
These demands can even extend beyond the duration of the funding, resulting in long lasting storage issues but also providing more opportunities for reuse.
For individual research projects this can be problematic as decisions on this level should be moved to institutional control \cite{dsb3lynch}.
Because assisted pregnancies are relatively rare and data gathering is a troublesome process reuse should be encouraged to make the effort useful and significant.

Lastly, lasting and reuse of data will also throw up barriers for the data deliverers.
Right now success percentages of clinics are being published as this is required by law, however they complain that the patient mix between clinics is unfair.
Clinics want to cooperate in the \project{} but they are scared that outcomes will be published in a way that will reflect directly on individual clinics.

%3 - Big data- How do your data grow?
%It also includes defining and recording appropriate metadata — such as experimental parameters and set-up — to allow for data interpretation
%This is best done when the data are captured. Indeed, descriptive metadata are often integrated within the experimental design. Description includes tracing provenance 

%1 - Big data the management revolution
%Perhaps even more important are skills in cleaning and organizing large data sets; the new kinds of data rarely come in structured formats. Visualization tools and techniques are also increasing in value.
%The best data scientists are also comfortable speaking the language of business and helping leaders reformulate their challenges in ways that big data can tackle
%The technologies are new and in some cases exotic. 
%It's too easy to mistake correlation for causation and to find misleading patterns in the data. 
%few things are more powerful for changing a decision-making culture than seeing a senior executive concede when data have disproved a hunch.
%They'll be valued not for their HiPPO-style answers but because they know what questions to ask
%When it comes to knowing which problems to tackle, of course, domain expertise remains critical
%Big data's power does not erase the need for vision or human insight.
\subsection{Interviews}
\label{security-interviews}

Next to the literature search interviews were held to provide examples for the laws and regulations which are quite abstract.

\paragraph{Set-up} 
\label{security-set-up}

Semi-structured interviews were performed with system security and medical registration system experts.
This interview technique leaves the interviewees free to roam to other subjects which might prove useful in the design of the \ivfsystem{}.
During the interviews firstly the vision of the \ivfsystem{} was explained in a few sentences.
After this the following questions were used to give structure to the interview, the term \emph{personal data} refers to identifying data.

\begin{itemize}
	\item What can we do to make sure we are not processing personal data?
	\item What are the criteria for something to be personal data or not?
	\item If personal data is being processed how can we comply to the extensive rules?
	\item How are things handled in existing registries?
	\item Are these registries also used for research?
	\item Aggregate data in public databases can become individually identifiable when the databases are integrated or the data are cross referenced, how do you account for this?
	\item Facing problems with getting go-ahead from ethical commissions for gathering data, how can a system like the \ivfsystem{} support in getting consent?
\end{itemize}

\subsubsection{First interview}
\label{security-first-interview}

This interview was with an expert on the topic of an intensive care registry in the Netherlands (NICE).
The NICE contains sensitive data where normally consent is required. 
However, patients at the IC are generally non responsive which means that getting consent is an unreasonable requirement and can be disregarded.

Considering consent there is a difference between historical data and \emph{active} data.
When using historical data it is difficult to get consent from each patient providing more room in the interpretation of the law.
For active data it is fairly easy to provide patients with a consent form when they visit the clinic thereby binding the researchers to acquire consent.

It is difficult to avoid processing personal data, \ie{} what is defined by `personal data' is open to interpretation.
Therefore, each of the used data items that might be debatable should be supported by a purpose/goal. % What sounds better?
Goals may vary but most of the time they describe why a certain data item is inevitable to use when doing research with the dataset.
A good guideline when creating a dataset is to take the minimum amount of data items while still being able to fulfil the research goal.
Some categories of data weigh more in a decision than others, \emph{sensitive} items (\eg{} race, sexual preference) are more likely to be turned down.
Once more, for ethical commissions the purpose of data collection and processing is leading in a decision, a well described protocol and application of standards (\eg{} NEN7510) are other points of interest.

It is impossible to guarantee that privacy is always kept.
This is due to factors like public datasets, news, and all other sorts of information sources.
When aggregating these datasets into one big dataset it becomes easier to discern individuals. 
For example, the Dutch queen is hospitalised and this information is published in a newspaper, from other sources (wikipedia, etc.) age and gender can be gathered.
With this information, even though the NICE is considered anonymous, the subset of possible patients can be reduced until in the end only one patient remains.
In order to avoid these kinds of data breaches some precautions can be taken but these will never be completely safe as there is a human factor.
Precautions that should be considered are: take notice of modern technical security techniques and implement those, keep external access to data either off-line or require to go through an internal administrator (\eg{} data extraction requests), aggregate data that is communicated to external sources which removes the likelihood of an individual being identified, when direct access to data is needed (\eg{} administrators, data mining research) use confidentiality documents, direct access to data is bound by location (\eg{} on one specific computer or inside a network).

As a side note, while talking about confidence people have with a system two topics came up.
The NICE makes it possible for ICs to benchmark themselves against data of other clinics.
However, all clinics remain anonymous which avoids discussion about accountability, \eg{} it is highly likely that the worst ranked IC receives less income once it is identified (less patients willing to go there, insurance is unwilling to pay).
The other topic is objectiveness of outcome measures.
Quality indicators that are presented by the system should never be directly influenced by humans, this introduces data playing problems where clinics artificially try to improve their scores by giving patients better outcomes than they actually have.